{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pump It Up Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from category_encoders import BinaryEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom helper function to get counts and percents by group\n",
    "def count_pct(dataframe, column):\n",
    "    # calculate grouped counts\n",
    "    grp_count = (\n",
    "        dataframe.groupby(column)\n",
    "        .size()\n",
    "        .reset_index(name = 'count')\n",
    "        .sort_values(['count'], ascending = False)\n",
    "        )\n",
    "    # use counts to generate percents\n",
    "    grp_pct = grp_count.assign(\n",
    "        pct = lambda dataframe: dataframe['count'].map(lambda count: count / np.nansum(grp_count['count'])) \n",
    "        )\n",
    "    return grp_pct\n",
    "\n",
    "def missing_value_plot(data):\n",
    "    plt.style.use('seaborn')\n",
    "    plt.figure(figsize = (15,10))\n",
    "    sns.heatmap(data.isnull(), yticklabels = False, cmap = 'plasma')\n",
    "    plt.title('Missing Values in Data Set');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:/Projects/pump_it_up/train_values.csv\")\n",
    "train_labels = pd.read_csv(\"D:/Projects/pump_it_up/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up text vars -- all text to lowercase\n",
    "train = train.applymap(lambda col:col.lower() if type(col) == str else col)\n",
    "\n",
    "train[['permit']] = pd.to_numeric(train['permit'])\n",
    "\n",
    "# clean up non-word characters\n",
    "numeric_cols = train.select_dtypes(include = np.number)\n",
    "\n",
    "text_cols = train.select_dtypes('object')\n",
    "text_cols = text_cols.apply(lambda col: col.str.replace('\\\\W+', '_'), axis = 1)\n",
    "\n",
    "train = pd.concat([numeric_cols, text_cols], axis = 1, ignore_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with 60% or more missing data -- amount_tsh and num_private\n",
    "train = train.loc[:, train.isin([' ','NULL',0, np.nan]).mean() < .6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Selection\n",
    "\n",
    "This is based on the exploratory data analysis done in pump_it_up_eda.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gps_height', 'longitude', 'latitude', 'region_code',\n",
       "       'district_code', 'population', 'permit', 'construction_year',\n",
       "       'date_recorded', 'funder', 'installer', 'wpt_name', 'basin',\n",
       "       'subvillage', 'region', 'lga', 'ward', 'recorded_by',\n",
       "       'scheme_management', 'scheme_name', 'extraction_type',\n",
       "       'extraction_type_group', 'extraction_type_class', 'management',\n",
       "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
       "       'source_class', 'waterpoint_type', 'waterpoint_type_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['funder', 'gps_height',\n",
    "               'installer', 'longitude', 'latitude', 'date_recorded'\n",
    "               'basin',  'region_code', 'district_code', 'lga',\n",
    "               'ward', 'scheme_management', 'management', \n",
    "               'permit', 'construction_year',\n",
    "               'extraction_type_group', \n",
    "               'payment',\n",
    "               'water_quality', 'quantity',\n",
    "               'source_type','waterpoint_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Missing Values\n",
    "\n",
    "We need to deal with some 0s masquerading as legitimate values before imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['construction_year'] == 0, 'construction_year'] = np.nan\n",
    "train.loc[train['funder'] == '0', 'funder'] = np.nan\n",
    "train.loc[train['gps_height'] == '0', 'gps_height'] = np.nan\n",
    "# train.loc[train['district_code'] == '0', 'district_code'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding\n",
    "Chose binary encoding for now-- large number of categories in some vars make one-hot problematic (very high dimensionality, results produce invariate variables, not to mention the practical problem of memory errors on my machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "be = BinaryEncoder(drop_invariant = True)\n",
    "be.fit(train)\n",
    "train = be.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=10, max_value = 2013)\n",
    "imp.fit(train)\n",
    "\n",
    "train = pd.DataFrame(imp.transform(train), columns = train.columns)\n",
    "train['construction_year'] = train['construction_year'].round(0)\n",
    "train['permit'] = train['permit'].round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = preprocessing.StandardScaler()\n",
    "ss.fit(train)\n",
    "\n",
    "scaled_train = ss.transform(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as balance_pipe\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.assign(\n",
    "    numeric_status_group = train_labels['status_group'].apply(lambda status_group: (0 if status_group == 'functional' \n",
    "                                                                       else 1 if status_group == 'non functional' \n",
    "                                                                       else 2)\n",
    "))\n",
    "# train.drop('id', axis = 1, inplace = True)\n",
    "train_labels.drop('id', axis = 1, inplace = True)\n",
    "train_labels.drop('status_group', axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set, train_set, test_label, train_label =  train_test_split(scaled_train, \n",
    "                                                                 train_labels.values.ravel(), \n",
    "                                                                 train_size = .20, \n",
    "                                                                 random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11880, 98)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_set, label = train_label)\n",
    "dtest = xgb.DMatrix(test_set, label = test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numeric_status_group</th>\n",
       "      <th>count</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24187</td>\n",
       "      <td>0.542918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17162</td>\n",
       "      <td>0.385230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3201</td>\n",
       "      <td>0.071852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numeric_status_group  count       pct\n",
       "0                     0  24187  0.542918\n",
       "1                     1  17162  0.385230\n",
       "2                     2   3201  0.071852"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_pct(train_label, 'numeric_status_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimented with smote to balance classes -- no significant improvement\n",
    "#smote_pipe = balance_pipe([('over_samp', SMOTE(sampling_strategy = {1 : 21000,\n",
    "#                                                                    2 : 7000}))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = smote_pipe.fit_resample(train_set, train_label)\n",
    "# smote = SMOTE('minority')\n",
    "# X, y = smote.fit_sample(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding weights offered a slight boost to performance\n",
    "cw = class_weight.compute_class_weight('balanced', np.unique(train_label), train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "              class_weight=array([0.61396618, 0.86528377, 4.63917526]),\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=10, eta=0.1, gamma=0, learning_rate=0.1,\n",
       "              max_delta_step=0, max_depth=15, min_child_weight=3, missing=None,\n",
       "              n_estimators=100, n_jobs=1, nthread=None, num_boost_rounds=200,\n",
       "              num_class=3, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_class = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                              max_depth = 15, \n",
    "                              min_child_weight = 3, \n",
    "                              eta = .1, \n",
    "                              num_class = 3,\n",
    "                              num_boost_rounds = 250,\n",
    "                              early_stopping_rounds = 10,\n",
    "                              class_weight = cw\n",
    "                             )\n",
    "#xgb_class.fit(X, y)\n",
    "xgb_class.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-merror:0.212121\n",
      "Will train until test-merror hasn't improved in 10 rounds.\n",
      "[1]\ttest-merror:0.208249\n",
      "[2]\ttest-merror:0.208333\n",
      "[3]\ttest-merror:0.20766\n",
      "[4]\ttest-merror:0.206313\n",
      "[5]\ttest-merror:0.20404\n",
      "[6]\ttest-merror:0.203451\n",
      "[7]\ttest-merror:0.202441\n",
      "[8]\ttest-merror:0.200084\n",
      "[9]\ttest-merror:0.199579\n",
      "[10]\ttest-merror:0.200168\n",
      "[11]\ttest-merror:0.199411\n",
      "[12]\ttest-merror:0.198148\n",
      "[13]\ttest-merror:0.197559\n",
      "[14]\ttest-merror:0.19798\n",
      "[15]\ttest-merror:0.196633\n",
      "[16]\ttest-merror:0.19697\n",
      "[17]\ttest-merror:0.196717\n",
      "[18]\ttest-merror:0.195791\n",
      "[19]\ttest-merror:0.194949\n",
      "[20]\ttest-merror:0.194192\n",
      "[21]\ttest-merror:0.193603\n",
      "[22]\ttest-merror:0.193182\n",
      "[23]\ttest-merror:0.194024\n",
      "[24]\ttest-merror:0.193939\n",
      "[25]\ttest-merror:0.193771\n",
      "[26]\ttest-merror:0.193603\n",
      "[27]\ttest-merror:0.194108\n",
      "[28]\ttest-merror:0.193855\n",
      "[29]\ttest-merror:0.193266\n",
      "[30]\ttest-merror:0.193182\n",
      "[31]\ttest-merror:0.193013\n",
      "[32]\ttest-merror:0.193182\n",
      "[33]\ttest-merror:0.192424\n",
      "[34]\ttest-merror:0.192424\n",
      "[35]\ttest-merror:0.19234\n",
      "[36]\ttest-merror:0.191835\n",
      "[37]\ttest-merror:0.19234\n",
      "[38]\ttest-merror:0.191919\n",
      "[39]\ttest-merror:0.191414\n",
      "[40]\ttest-merror:0.191582\n",
      "[41]\ttest-merror:0.191414\n",
      "[42]\ttest-merror:0.191414\n",
      "[43]\ttest-merror:0.191414\n",
      "[44]\ttest-merror:0.19133\n",
      "[45]\ttest-merror:0.191414\n",
      "[46]\ttest-merror:0.191162\n",
      "[47]\ttest-merror:0.190404\n",
      "[48]\ttest-merror:0.190909\n",
      "[49]\ttest-merror:0.190993\n",
      "[50]\ttest-merror:0.19032\n",
      "[51]\ttest-merror:0.191162\n",
      "[52]\ttest-merror:0.190741\n",
      "[53]\ttest-merror:0.191077\n",
      "[54]\ttest-merror:0.191414\n",
      "[55]\ttest-merror:0.191667\n",
      "[56]\ttest-merror:0.192003\n",
      "[57]\ttest-merror:0.19234\n",
      "[58]\ttest-merror:0.192003\n",
      "[59]\ttest-merror:0.192256\n",
      "[60]\ttest-merror:0.192003\n",
      "Stopping. Best iteration:\n",
      "[50]\ttest-merror:0.19032\n",
      "\n",
      "Best MERROR: 0.19 with 51 rounds\n"
     ]
    }
   ],
   "source": [
    " params = {\n",
    "     # Parameters to tune\n",
    "     'max_depth' : 15,\n",
    "     'min_child_weight' : 3,\n",
    "     'eta' : .1,\n",
    "     'objective' :'multi:softmax',\n",
    "     'num_class' : 3,\n",
    "     #'class_weight' : cw,\n",
    "     'eval_metric' : 'merror' # for multi-class classification problems, use merror or mlogloss\n",
    " }\n",
    "\n",
    " num_boost_round = 999 # high number of boost rounds allows early_stopping_rounds to do its work\n",
    "\n",
    " model = xgb.train(\n",
    "     params,\n",
    "     dtrain,\n",
    "     num_boost_round = num_boost_round,\n",
    "     evals=[(dtest, \"test\")],\n",
    "     early_stopping_rounds = 10\n",
    " )\n",
    "\n",
    " print(\"Best MERROR: {:.2f} with {} rounds\".format(\n",
    "                  model.best_score,\n",
    "                  model.best_iteration+1))\n",
    "\n",
    " preds = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807996632996633\n"
     ]
    }
   ],
   "source": [
    "# Attained prediction accuracy on the training set\n",
    "cm = confusion_matrix(preds, test_label)\n",
    "acc = cm.diagonal().sum()/cm.sum()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5751,  914,  443],\n",
       "       [ 582, 3551,  146],\n",
       "       [ 148,   48,  297]], dtype=int64)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(scaled_train, label = train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bayesian optimization function for xgboost\n",
    "# specify the parameters to tune as keyword arguments\n",
    "def optimize_xgb(max_depth, min_child_weight, gamma, boost_rounds, eta):\n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'min_child_weight': int(min_child_weight),\n",
    "              'subsample': 1,\n",
    "              'gamma' : gamma,\n",
    "              'eta': eta,\n",
    "              'objective' :'multi:softmax',\n",
    "              'num_class' : 3,\n",
    "              'eval_metric': 'merror',\n",
    "              'class_weight' : cw,\n",
    "              'early_stopping_rounds' : 10\n",
    "             }\n",
    "    # Cross validating with the specified parameters in 5 folds and max 250 iterations\n",
    "    cv_result = xgb.cv(params, dtrain, nfold = 8)\n",
    "    # return negative merror -- setting to inverse means bayesian maximization returns params that generate lowest merror\n",
    "    return -1 * cv_result['train-merror-mean'].iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo = BayesianOptimization(optimize_xgb, {'max_depth' : (1, 50),\n",
    "                                             'min_child_weight' : (0, 15),\n",
    "                                             'gamma' : (0,1)\n",
    "                                             'boost_rounds' : (1, 500),\n",
    "                                             'eta' : (.005, .5)\n",
    "                                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | boost_... |   gamma   | max_depth | min_ch... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2178  \u001b[0m | \u001b[0m 248.0   \u001b[0m | \u001b[0m 0.7077  \u001b[0m | \u001b[0m 8.94    \u001b[0m | \u001b[0m 2.599   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.09946 \u001b[0m | \u001b[95m 81.13   \u001b[0m | \u001b[95m 0.4673  \u001b[0m | \u001b[95m 19.54   \u001b[0m | \u001b[95m 3.831   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.05393 \u001b[0m | \u001b[95m 74.6    \u001b[0m | \u001b[95m 0.3535  \u001b[0m | \u001b[95m 17.38   \u001b[0m | \u001b[95m 0.9804  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1174  \u001b[0m | \u001b[0m 148.4   \u001b[0m | \u001b[0m 0.8317  \u001b[0m | \u001b[0m 19.62   \u001b[0m | \u001b[0m 4.033   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.09887 \u001b[0m | \u001b[0m 69.75   \u001b[0m | \u001b[0m 0.4496  \u001b[0m | \u001b[0m 19.66   \u001b[0m | \u001b[0m 3.496   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.09759 \u001b[0m | \u001b[0m 29.28   \u001b[0m | \u001b[0m 0.06659 \u001b[0m | \u001b[0m 18.58   \u001b[0m | \u001b[0m 3.628   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.08399 \u001b[0m | \u001b[0m 78.86   \u001b[0m | \u001b[0m 0.9535  \u001b[0m | \u001b[0m 18.71   \u001b[0m | \u001b[0m 1.76    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1829  \u001b[0m | \u001b[0m 42.69   \u001b[0m | \u001b[0m 0.7063  \u001b[0m | \u001b[0m 10.88   \u001b[0m | \u001b[0m 3.489   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2201  \u001b[0m | \u001b[0m 196.5   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.217   \u001b[0m | \u001b[0m 122.7   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.03035 \u001b[0m | \u001b[95m 220.3   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 20.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.03035 \u001b[0m | \u001b[0m 180.3   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.03035 \u001b[0m | \u001b[0m 250.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1139  \u001b[0m | \u001b[0m 239.2   \u001b[0m | \u001b[0m 0.5953  \u001b[0m | \u001b[0m 19.99   \u001b[0m | \u001b[0m 4.491   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.217   \u001b[0m | \u001b[0m 25.78   \u001b[0m | \u001b[0m 0.000777\u001b[0m | \u001b[0m 8.051   \u001b[0m | \u001b[0m 0.4042  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2193  \u001b[0m | \u001b[0m 79.9    \u001b[0m | \u001b[0m 0.1236  \u001b[0m | \u001b[0m 8.122   \u001b[0m | \u001b[0m 4.549   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.03035 \u001b[0m | \u001b[0m 111.3   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.04108 \u001b[0m | \u001b[0m 43.57   \u001b[0m | \u001b[0m 0.09038 \u001b[0m | \u001b[0m 18.95   \u001b[0m | \u001b[0m 0.07928 \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.03035 \u001b[0m | \u001b[0m 201.8   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.03523 \u001b[0m | \u001b[0m 136.1   \u001b[0m | \u001b[0m 0.1182  \u001b[0m | \u001b[0m 19.91   \u001b[0m | \u001b[0m 0.03171 \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.03512 \u001b[0m | \u001b[0m 157.3   \u001b[0m | \u001b[0m 0.1209  \u001b[0m | \u001b[0m 19.54   \u001b[0m | \u001b[0m 0.7093  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.03539 \u001b[0m | \u001b[0m 88.18   \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 19.98   \u001b[0m | \u001b[0m 0.2738  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.03521 \u001b[0m | \u001b[0m 239.5   \u001b[0m | \u001b[0m 0.06832 \u001b[0m | \u001b[0m 19.8    \u001b[0m | \u001b[0m 0.05038 \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.03505 \u001b[0m | \u001b[0m 75.72   \u001b[0m | \u001b[0m 0.05185 \u001b[0m | \u001b[0m 19.92   \u001b[0m | \u001b[0m 0.2805  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.217   \u001b[0m | \u001b[0m 164.0   \u001b[0m | \u001b[0m 0.09216 \u001b[0m | \u001b[0m 8.49    \u001b[0m | \u001b[0m 0.1608  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.06569 \u001b[0m | \u001b[0m 166.3   \u001b[0m | \u001b[0m 0.8682  \u001b[0m | \u001b[0m 19.78   \u001b[0m | \u001b[0m 0.2627  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.04523 \u001b[0m | \u001b[0m 26.67   \u001b[0m | \u001b[0m 0.4792  \u001b[0m | \u001b[0m 19.57   \u001b[0m | \u001b[0m 0.009431\u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.03489 \u001b[0m | \u001b[0m 147.4   \u001b[0m | \u001b[0m 0.005539\u001b[0m | \u001b[0m 19.45   \u001b[0m | \u001b[0m 0.0888  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.06055 \u001b[0m | \u001b[0m 56.5    \u001b[0m | \u001b[0m 0.1343  \u001b[0m | \u001b[0m 16.46   \u001b[0m | \u001b[0m 0.03775 \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.03517 \u001b[0m | \u001b[0m 193.1   \u001b[0m | \u001b[0m 0.06567 \u001b[0m | \u001b[0m 19.8    \u001b[0m | \u001b[0m 0.08229 \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.03524 \u001b[0m | \u001b[0m 33.96   \u001b[0m | \u001b[0m 0.08693 \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 0.1182  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.1194  \u001b[0m | \u001b[0m 189.9   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.03529 \u001b[0m | \u001b[0m 126.1   \u001b[0m | \u001b[0m 0.08649 \u001b[0m | \u001b[0m 19.6    \u001b[0m | \u001b[0m 0.007626\u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.039   \u001b[0m | \u001b[0m 154.1   \u001b[0m | \u001b[0m 0.3194  \u001b[0m | \u001b[0m 19.94   \u001b[0m | \u001b[0m 0.1612  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.03521 \u001b[0m | \u001b[0m 97.77   \u001b[0m | \u001b[0m 0.1157  \u001b[0m | \u001b[0m 19.6    \u001b[0m | \u001b[0m 0.6525  \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "xgb_bo.maximize(n_iter = 27, init_points = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boost_rounds': 220.34581122246493, 'gamma': 0.0, 'max_depth': 20.0, 'min_child_weight': 0.0}\n"
     ]
    }
   ],
   "source": [
    "#Extracting the best parameters\n",
    "params = xgb_bo.max['params']\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third submission\n",
    "\n",
    "params = {\n",
    "    # tuned parameters\n",
    "    'max_depth' : 15,\n",
    "    'min_child_weight' : 3,\n",
    "    'gamma' : .0,\n",
    "    'eta' : .1,\n",
    "    'subsample' : 1,\n",
    "    'objective' :'multi:softmax',\n",
    "    'class_weight' : cw,\n",
    "    'num_class' : 3,\n",
    "    'eval_metric' : 'merror' # for multi-class classification problems, use merror or mlogloss\n",
    "}\n",
    "\n",
    "#num_boost_round = 250 # high number of boost rounds allows early_stopping_rounds to do its work\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round = 500,\n",
    "    early_stopping_rounds = 10,\n",
    "    evals=[(dtest, \"test\")]\n",
    ")\n",
    "\n",
    "#print(\"Best MERROR: {:.2f} with {} rounds\".format(\n",
    "#                 model.best_score,\n",
    "#                 model.best_iteration+1))\n",
    "\n",
    "#preds = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv(\"D:/Projects/pump_it_up/test_values.csv\")\n",
    "\n",
    "test = test[['funder', 'gps_height',\n",
    "               'installer', 'longitude', 'latitude',\n",
    "               'basin',  'region_code', 'district_code', 'lga',\n",
    "               'ward', 'scheme_management', 'management', \n",
    "               'permit', 'construction_year',\n",
    "               'extraction_type_group', 'extraction_type_class',\n",
    "               'payment',\n",
    "               'water_quality', 'quality_group', 'quantity', 'quantity_group',\n",
    "               'source', 'source_type','source_class', 'waterpoint_type', 'waterpoint_type_group']]\n",
    "\n",
    " # clean up text vars -- all text to lowercase\n",
    "test = test.applymap(lambda col:col.lower() if type(col) == str else col)\n",
    "\n",
    "test[['permit']] = pd.to_numeric(test['permit'])\n",
    "\n",
    "# clean up non-word characters\n",
    "numeric_cols = test.select_dtypes(include = np.number)\n",
    "\n",
    "text_cols = test.select_dtypes('object')\n",
    "text_cols = text_cols.apply(lambda col: col.str.replace('\\\\W+', '_'), axis = 1)\n",
    "\n",
    "test = pd.concat([numeric_cols, text_cols], axis = 1, ignore_index = False)\n",
    "\n",
    "test.loc[test['construction_year'] == 0, 'construction_year'] = np.nan\n",
    "test.loc[test['funder'] == '0', 'funder'] = np.nan\n",
    "test.loc[test['gps_height'] == '0', 'gps_height'] = np.nan\n",
    "    \n",
    "# binary encode test set\n",
    "test = be.transform(test)\n",
    "    \n",
    "# impute test set\n",
    "test = pd.DataFrame(imp.transform(test), columns = test.columns)\n",
    "test['construction_year'] = test['construction_year'].round(0)\n",
    "test['permit'] = test['permit'].round(0)\n",
    "# ensure same column names\n",
    "test = test.loc[:,train.columns.tolist()]\n",
    "# scale test set\n",
    "scaled_test = ss.transform(test)\n",
    "\n",
    "test_dmatrix = xgb.DMatrix(scaled_test)\n",
    "\n",
    "submit_preds = model.predict(test_dmatrix)\n",
    "\n",
    "submit_preds = model.predict(test_dmatrix)\n",
    "\n",
    "test_ids = pd.read_csv(\"D:/Projects/pump_it_up/test_values.csv\")\n",
    "test_ids = test_ids[['id']]\n",
    "test_ids = test_ids.assign(numeric_status_group = submit_preds)\n",
    "\n",
    "test_ids = test_ids.assign(\n",
    "    status_group = test_ids['numeric_status_group'].apply(lambda status_group: ('functional' if status_group == 0\n",
    "                                                                           else 'non functional' if status_group == 1 \n",
    "                                                                           else 'functional needs repair')\n",
    "))\n",
    "\n",
    "pd.DataFrame.to_csv(test_ids[['id', 'status_group']], \"D:/Projects/pump_it_up/submit.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
